{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# LangFuse를 통한 관찰 가능성과 RAGAS를 통한 평가로 Strands Agent 평가하기\n",
    "\n",
    "## 개요\n",
    "이 예제에서는 관찰 가능성과 평가 기능을 갖춘 에이전트를 구축하는 방법을 보여드리겠습니다. [Langfuse](https://langfuse.com/)를 활용하여 Strands Agent 추적을 처리하고 [Ragas](https://www.ragas.io/) 메트릭을 사용하여 에이전트의 성능을 평가하겠습니다. 주요 초점은 SDK에서 생성된 추적을 사용하여 에이전트가 생성한 응답의 품질을 평가하는 에이전트 평가입니다.\n",
    "\n",
    "Strands Agents는 LangFuse와의 관찰 가능성을 위한 내장 지원을 제공합니다. 이 노트북에서는 Langfuse에서 데이터를 수집하고, Ragas에서 필요한 변환을 적용하고, 평가를 수행하고, 마지막으로 점수를 추적에 다시 연결하는 방법을 보여줍니다. 추적과 점수를 한 곳에 두면 더 깊이 있는 분석, 트렌드 분석 및 지속적인 개선이 가능합니다.\n",
    "\n",
    "\n",
    "## 에이전트 세부사항\n",
    "<div style=\"float: left; margin-right: 20px;\">\n",
    "    \n",
    "|기능                |설명                                               |\n",
    "|--------------------|---------------------------------------------------|\n",
    "|사용된 네이티브 도구 |current_time, retrieve                              |\n",
    "|생성된 사용자 정의 도구|create_booking, get_booking_details, delete_booking |\n",
    "|에이전트 구조        |단일 에이전트 아키텍처                              |\n",
    "|사용된 AWS 서비스    |Amazon Bedrock Knowledge Base, Amazon DynamoDB      |\n",
    "|통합                |관찰 가능성을 위한 LangFuse와 관찰을 위한 Ragas      |\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 아키텍처\n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/architecture.png\" width=\"75%\" />\n",
    "</div>\n",
    "\n",
    "## 주요 기능\n",
    "- Langfuse에서 Strands 에이전트 상호작용 추적을 가져옵니다. 이러한 추적을 오프라인으로 저장하고 Langfuse 없이 여기서 사용할 수도 있습니다.\n",
    "- 에이전트, 도구 및 RAG를 위한 전문 메트릭을 사용하여 대화를 평가합니다\n",
    "- 완전한 피드백 루프를 위해 평가 점수를 Langfuse로 다시 푸시합니다\n",
    "- 단일 턴(컨텍스트 포함)과 다중 턴 대화를 모두 평가합니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 설정 및 사전 요구사항\n",
    "\n",
    "### 사전 요구사항\n",
    "* Python 3.10+\n",
    "* AWS 계정\n",
    "* Amazon Bedrock에서 Anthropic Claude 3.7 활성화\n",
    "* Amazon Bedrock Knowledge Base, Amazon S3 버킷 및 Amazon DynamoDB 생성 권한이 있는 IAM 역할\n",
    "* LangFuse 키\n",
    "\n",
    "이제 Strands Agent에 필요한 패키지들을 설치하겠습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 필요한 패키지 설치\n",
    "!pip install --upgrade --force-reinstall -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 최신 버전의 Strands Agents Tools를 실행하고 있는지 확인하겠습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install strands-agents-tools>=0.2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 의존성 패키지 가져오기\n",
    "\n",
    "이제 의존성 패키지들을 가져오겠습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from langfuse import Langfuse\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    context_precision,\n",
    "    context_recall,\n",
    "    faithfulness,\n",
    "    answer_correctness\n",
    ")\n",
    "from strands import Agent, tool\n",
    "from strands_tools import current_time, retrieve\n",
    "from strands.models import BedrockModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangFuse 설정\n",
    "\n",
    "관찰 가능성을 위해 LangFuse를 설정하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangFuse 환경 변수 설정\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"your-public-key\"  # 실제 키로 교체\n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"your-secret-key\"  # 실제 키로 교체\n",
    "os.environ[\"LANGFUSE_HOST\"] = \"https://cloud.langfuse.com\"  # 또는 자체 호스팅 인스턴스\n",
    "\n",
    "# LangFuse 클라이언트 초기화\n",
    "langfuse = Langfuse()\n",
    "print(\"✅ LangFuse 클라이언트가 초기화되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사용자 정의 도구 정의\n",
    "\n",
    "레스토랑 예약 시스템을 위한 사용자 정의 도구들을 정의하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def create_booking(restaurant_name: str, date: str, time: str, party_size: int, customer_name: str) -> str:\n",
    "    \"\"\"새로운 레스토랑 예약을 생성합니다.\n",
    "    \n",
    "    Args:\n",
    "        restaurant_name: 레스토랑 이름\n",
    "        date: 예약 날짜 (YYYY-MM-DD 형식)\n",
    "        time: 예약 시간 (HH:MM 형식)\n",
    "        party_size: 인원 수\n",
    "        customer_name: 고객 이름\n",
    "    \n",
    "    Returns:\n",
    "        예약 확인 메시지\n",
    "    \"\"\"\n",
    "    booking_id = f\"BK{datetime.now().strftime('%Y%m%d%H%M%S')}\"\n",
    "    return f\"예약이 완료되었습니다! 예약 ID: {booking_id}, 레스토랑: {restaurant_name}, 날짜: {date}, 시간: {time}, 인원: {party_size}명, 고객: {customer_name}\"\n",
    "\n",
    "@tool\n",
    "def get_booking_details(booking_id: str) -> str:\n",
    "    \"\"\"예약 ID로 예약 세부사항을 조회합니다.\n",
    "    \n",
    "    Args:\n",
    "        booking_id: 예약 ID\n",
    "    \n",
    "    Returns:\n",
    "        예약 세부사항\n",
    "    \"\"\"\n",
    "    # 더미 데이터 반환\n",
    "    return f\"예약 ID {booking_id}: 레스토랑 '맛있는 집', 2024-01-15 19:00, 4명, 고객: 김철수\"\n",
    "\n",
    "@tool\n",
    "def delete_booking(booking_id: str) -> str:\n",
    "    \"\"\"예약을 취소합니다.\n",
    "    \n",
    "    Args:\n",
    "        booking_id: 취소할 예약 ID\n",
    "    \n",
    "    Returns:\n",
    "        취소 확인 메시지\n",
    "    \"\"\"\n",
    "    return f\"예약 ID {booking_id}가 성공적으로 취소되었습니다.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 관찰 가능성이 적용된 에이전트 생성\n",
    "\n",
    "LangFuse 추적이 활성화된 레스토랑 어시스턴트 에이전트를 생성하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시스템 프롬프트 정의\n",
    "system_prompt = \"\"\"\n",
    "당신은 도움이 되는 레스토랑 어시스턴트입니다. 다음 기능을 제공할 수 있습니다:\n",
    "\n",
    "1. 레스토랑 예약 생성\n",
    "2. 예약 세부사항 조회\n",
    "3. 예약 취소\n",
    "4. 레스토랑 정보 검색\n",
    "5. 현재 시간 확인\n",
    "\n",
    "항상 정중하고 도움이 되는 방식으로 응답하며, 필요한 정보가 부족한 경우 고객에게 추가 정보를 요청하세요.\n",
    "\"\"\"\n",
    "\n",
    "# Bedrock 모델 구성\n",
    "model = BedrockModel(\n",
    "    model_id=\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
    "    additional_request_fields={\n",
    "        \"thinking\": {\n",
    "            \"type\": \"disabled\"\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# LangFuse 추적이 활성화된 에이전트 생성\n",
    "restaurant_agent = Agent(\n",
    "    model=model,\n",
    "    system_prompt=system_prompt,\n",
    "    tools=[current_time, retrieve, create_booking, get_booking_details, delete_booking],\n",
    "    langfuse_config={\n",
    "        \"public_key\": os.environ.get(\"LANGFUSE_PUBLIC_KEY\"),\n",
    "        \"secret_key\": os.environ.get(\"LANGFUSE_SECRET_KEY\"),\n",
    "        \"host\": os.environ.get(\"LANGFUSE_HOST\")\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"✅ 관찰 가능성이 적용된 레스토랑 어시스턴트가 생성되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 에이전트 테스트 및 추적 생성\n",
    "\n",
    "평가를 위한 추적 데이터를 생성하기 위해 에이전트와 몇 가지 상호작용을 수행하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 대화들\n",
    "test_conversations = [\n",
    "    \"안녕하세요! 내일 저녁 7시에 4명이서 식사할 수 있는 좋은 레스토랑을 예약하고 싶습니다.\",\n",
    "    \"예약 ID BK20240115190000의 세부사항을 확인해주세요.\",\n",
    "    \"현재 시간이 몇 시인지 알려주세요.\",\n",
    "    \"예약을 취소하고 싶습니다. 예약 ID는 BK20240115190000입니다.\",\n",
    "    \"서울에 있는 이탈리안 레스토랑을 찾아주세요.\"\n",
    "]\n",
    "\n",
    "print(\"테스트 대화 실행 중...\")\n",
    "for i, conversation in enumerate(test_conversations, 1):\n",
    "    print(f\"\\n=== 대화 {i} ===\")\n",
    "    print(f\"사용자: {conversation}\")\n",
    "    \n",
    "    try:\n",
    "        response = restaurant_agent(conversation)\n",
    "        print(f\"어시스턴트: {response}\")\n",
    "    except Exception as e:\n",
    "        print(f\"오류 발생: {e}\")\n",
    "\n",
    "print(\"\\n✅ 모든 테스트 대화가 완료되었습니다. 추적이 LangFuse에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangFuse에서 추적 데이터 가져오기\n",
    "\n",
    "평가를 위해 LangFuse에서 추적 데이터를 가져오겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_traces_from_langfuse(limit=10):\n",
    "    \"\"\"LangFuse에서 최근 추적들을 가져옵니다.\"\"\"\n",
    "    try:\n",
    "        traces = langfuse.get_traces(limit=limit)\n",
    "        \n",
    "        evaluation_data = []\n",
    "        for trace in traces.data:\n",
    "            # 추적에서 필요한 정보 추출\n",
    "            if hasattr(trace, 'input') and hasattr(trace, 'output'):\n",
    "                evaluation_data.append({\n",
    "                    'trace_id': trace.id,\n",
    "                    'question': str(trace.input) if trace.input else \"\",\n",
    "                    'answer': str(trace.output) if trace.output else \"\",\n",
    "                    'contexts': [],  # RAG 컨텍스트가 있다면 여기에 추가\n",
    "                    'ground_truth': \"\"  # 실제 환경에서는 정답 데이터 제공\n",
    "                })\n",
    "        \n",
    "        return evaluation_data\n",
    "    except Exception as e:\n",
    "        print(f\"추적 가져오기 오류: {e}\")\n",
    "        return []\n",
    "\n",
    "# 추적 데이터 가져오기\n",
    "traces_data = fetch_traces_from_langfuse()\n",
    "print(f\"✅ {len(traces_data)}개의 추적을 가져왔습니다.\")\n",
    "\n",
    "# 데이터 미리보기\n",
    "if traces_data:\n",
    "    df = pd.DataFrame(traces_data)\n",
    "    print(\"\\n추적 데이터 미리보기:\")\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAGAS를 사용한 평가\n",
    "\n",
    "수집된 추적 데이터를 RAGAS 메트릭으로 평가하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_with_ragas(evaluation_data):\n",
    "    \"\"\"RAGAS 메트릭을 사용하여 에이전트 성능을 평가합니다.\"\"\"\n",
    "    if not evaluation_data:\n",
    "        print(\"평가할 데이터가 없습니다.\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # 평가 데이터셋 준비\n",
    "        dataset = pd.DataFrame(evaluation_data)\n",
    "        \n",
    "        # 빈 값 처리\n",
    "        dataset = dataset.fillna(\"\")\n",
    "        \n",
    "        # RAGAS 평가 실행\n",
    "        print(\"RAGAS 평가 실행 중...\")\n",
    "        \n",
    "        # 사용할 메트릭 선택 (컨텍스트가 있는 경우에만 일부 메트릭 사용)\n",
    "        metrics_to_use = [answer_relevancy]\n",
    "        \n",
    "        # 컨텍스트가 있는 데이터가 있다면 추가 메트릭 사용\n",
    "        has_context = any(row['contexts'] for row in evaluation_data if row['contexts'])\n",
    "        if has_context:\n",
    "            metrics_to_use.extend([context_precision, context_recall, faithfulness])\n",
    "        \n",
    "        # 정답이 있는 데이터가 있다면 정확성 메트릭 추가\n",
    "        has_ground_truth = any(row['ground_truth'] for row in evaluation_data if row['ground_truth'])\n",
    "        if has_ground_truth:\n",
    "            metrics_to_use.append(answer_correctness)\n",
    "        \n",
    "        # 평가 실행\n",
    "        result = evaluate(\n",
    "            dataset=dataset,\n",
    "            metrics=metrics_to_use\n",
    "        )\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"RAGAS 평가 오류: {e}\")\n",
    "        return None\n",
    "\n",
    "# 평가 실행\n",
    "if traces_data:\n",
    "    evaluation_result = evaluate_with_ragas(traces_data)\n",
    "    \n",
    "    if evaluation_result:\n",
    "        print(\"\\n✅ 평가 완료!\")\n",
    "        print(\"\\n평가 결과:\")\n",
    "        for metric, score in evaluation_result.items():\n",
    "            print(f\"{metric}: {score:.4f}\")\n",
    "    else:\n",
    "        print(\"평가를 완료할 수 없습니다.\")\n",
    "else:\n",
    "    print(\"평가할 추적 데이터가 없습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 평가 점수를 LangFuse로 다시 전송\n",
    "\n",
    "평가 결과를 LangFuse의 해당 추적에 다시 연결하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def push_scores_to_langfuse(traces_data, evaluation_result):\n",
    "    \"\"\"평가 점수를 LangFuse 추적에 다시 연결합니다.\"\"\"\n",
    "    if not evaluation_result or not traces_data:\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # 각 추적에 대해 점수 업데이트\n",
    "        for i, trace_data in enumerate(traces_data):\n",
    "            trace_id = trace_data['trace_id']\n",
    "            \n",
    "            # 해당 추적의 점수들 추출\n",
    "            for metric_name, scores in evaluation_result.items():\n",
    "                if isinstance(scores, list) and i < len(scores):\n",
    "                    score_value = scores[i]\n",
    "                    \n",
    "                    # LangFuse에 점수 추가\n",
    "                    langfuse.score(\n",
    "                        trace_id=trace_id,\n",
    "                        name=metric_name,\n",
    "                        value=float(score_value),\n",
    "                        comment=f\"RAGAS {metric_name} 평가 점수\"\n",
    "                    )\n",
    "        \n",
    "        print(\"✅ 평가 점수가 LangFuse에 성공적으로 업로드되었습니다.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"점수 업로드 오류: {e}\")\n",
    "\n",
    "# 점수를 LangFuse로 전송\n",
    "if traces_data and evaluation_result:\n",
    "    push_scores_to_langfuse(traces_data, evaluation_result)\n",
    "else:\n",
    "    print(\"전송할 평가 결과가 없습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 평가 결과 분석\n",
    "\n",
    "평가 결과를 시각화하고 분석하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_evaluation_results(evaluation_result, traces_data):\n",
    "    \"\"\"평가 결과를 분석하고 인사이트를 제공합니다.\"\"\"\n",
    "    if not evaluation_result:\n",
    "        return\n",
    "    \n",
    "    print(\"=== 평가 결과 분석 ===\")\n",
    "    \n",
    "    # 전체 성능 요약\n",
    "    print(\"\\n📊 전체 성능 요약:\")\n",
    "    for metric, score in evaluation_result.items():\n",
    "        if isinstance(score, (int, float)):\n",
    "            print(f\"  {metric}: {score:.4f}\")\n",
    "            \n",
    "            # 성능 해석\n",
    "            if score >= 0.8:\n",
    "                performance = \"우수\"\n",
    "            elif score >= 0.6:\n",
    "                performance = \"양호\"\n",
    "            elif score >= 0.4:\n",
    "                performance = \"보통\"\n",
    "            else:\n",
    "                performance = \"개선 필요\"\n",
    "            \n",
    "            print(f\"    → 성능 수준: {performance}\")\n",
    "    \n",
    "    # 개선 권장사항\n",
    "    print(\"\\n💡 개선 권장사항:\")\n",
    "    \n",
    "    for metric, score in evaluation_result.items():\n",
    "        if isinstance(score, (int, float)) and score < 0.7:\n",
    "            if 'relevancy' in metric.lower():\n",
    "                print(\"  - 답변 관련성 개선: 질문에 더 직접적으로 답변하도록 프롬프트 조정\")\n",
    "            elif 'precision' in metric.lower():\n",
    "                print(\"  - 컨텍스트 정밀도 개선: 더 관련성 높은 정보 검색\")\n",
    "            elif 'recall' in metric.lower():\n",
    "                print(\"  - 컨텍스트 재현율 개선: 더 포괄적인 정보 검색\")\n",
    "            elif 'faithfulness' in metric.lower():\n",
    "                print(\"  - 충실도 개선: 제공된 컨텍스트에 더 충실한 답변 생성\")\n",
    "            elif 'correctness' in metric.lower():\n",
    "                print(\"  - 정확성 개선: 사실 확인 및 도메인 지식 강화\")\n",
    "    \n",
    "    # 데이터 품질 분석\n",
    "    print(\"\\n📈 데이터 품질 분석:\")\n",
    "    print(f\"  - 평가된 대화 수: {len(traces_data)}\")\n",
    "    \n",
    "    context_count = sum(1 for trace in traces_data if trace.get('contexts'))\n",
    "    print(f\"  - 컨텍스트가 있는 대화: {context_count}\")\n",
    "    \n",
    "    ground_truth_count = sum(1 for trace in traces_data if trace.get('ground_truth'))\n",
    "    print(f\"  - 정답이 있는 대화: {ground_truth_count}\")\n",
    "\n",
    "# 결과 분석 실행\n",
    "if evaluation_result and traces_data:\n",
    "    analyze_evaluation_results(evaluation_result, traces_data)\n",
    "else:\n",
    "    print(\"분석할 평가 결과가 없습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결론\n",
    "\n",
    "이 노트북에서는 LangFuse와 RAGAS를 사용하여 Strands Agents의 관찰 가능성과 평가를 구현하는 방법을 배웠습니다. 주요 학습 내용:\n",
    "\n",
    "1. **관찰 가능성 설정**: LangFuse를 통한 에이전트 추적 수집\n",
    "2. **평가 메트릭**: RAGAS를 사용한 다양한 성능 지표 측정\n",
    "3. **피드백 루프**: 평가 결과를 추적 시스템에 다시 연결\n",
    "4. **성능 분석**: 결과 해석 및 개선 방향 제시\n",
    "\n",
    "### 활용 방안\n",
    "\n",
    "- **지속적 개선**: 정기적인 평가를 통한 에이전트 성능 모니터링\n",
    "- **A/B 테스트**: 다양한 프롬프트나 모델 비교 평가\n",
    "- **품질 보증**: 프로덕션 배포 전 성능 검증\n",
    "- **사용자 경험 최적화**: 실제 사용 패턴 분석을 통한 개선\n",
    "\n",
    "### 다음 단계\n",
    "\n",
    "- 더 많은 RAGAS 메트릭 탐색\n",
    "- 사용자 정의 평가 메트릭 개발\n",
    "- 자동화된 평가 파이프라인 구축\n",
    "- 실시간 모니터링 대시보드 구성\n",
    "\n",
    "관찰 가능성과 평가를 통해 더욱 신뢰할 수 있고 효과적인 AI 에이전트를 구축할 수 있습니다! 🚀"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",\n",
   "language": "python",\n",
   "name": "python3"\n  },\n  "language_info": {\n   "codemirror_mode": {\n    "name": "ipython",\n    "version": 3\n   },\n   "file_extension": ".py",\n   "mimetype": "text/x-python",\n   "name": "python",\n   "nbconvert_exporter": "python",\n   "pygments_lexer": "ipython3",\n   "version": "3.12.9"\n  }\n },\n "nbformat": 4,\n "nbformat_minor": 4\n}